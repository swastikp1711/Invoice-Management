{"version":3,"file":"documentAnalysisClient.js","sourceRoot":"","sources":["../../src/documentAnalysisClient.ts"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC;AAGlC,OAAO,EAAE,mBAAmB,EAAE,MAAM,qBAAqB,CAAC;AAE1D,OAAO,EAAE,2BAA2B,EAAE,WAAW,EAAE,MAAM,aAAa,CAAC;AAOvE,OAAO,EAAE,OAAO,EAAE,MAAM,+BAA+B,CAAC;AACxD,OAAO,EAML,4BAA4B,EAC5B,oCAAoC,GACrC,MAAM,gBAAgB,CAAC;AACxB,OAAO,EAAoB,GAAG,EAAE,MAAM,mBAAmB,CAAC;AAI1D,OAAO,EAAE,iBAAiB,EAAE,OAAO,EAAE,UAAU,EAAE,MAAM,QAAQ,CAAC;AAIhE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA6BG;AACH,MAAM,OAAO,sBAAsB;IA8DjC,YACE,QAAgB,EAChB,UAA2C,EAC3C,UAAyC,EAAE;QAE3C,IAAI,CAAC,WAAW,GAAG,iBAAiB,CAAC,QAAQ,EAAE,UAAU,EAAE,OAAO,CAAC,CAAC;QACpE,IAAI,CAAC,QAAQ,GAAG,mBAAmB,CAAC;YAClC,WAAW,EAAE,2BAA2B;YACxC,cAAc,EAAE,WAAW;YAC3B,SAAS,EAAE,6BAA6B;SACzC,CAAC,CAAC;IACL,CAAC;IAsHM,KAAK,CAAC,oBAAoB,CAC/B,KAAsC,EACtC,QAAmC,EACnC,UAA2C,EAAE;QAE7C,OAAO,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAC3B,6CAA6C,EAC7C,OAAO;QACP,+GAA+G;QAC/G,wDAAwD;QACxD,IAAI,CAAC,OAAO,CAAC,IAAI,CACf,IAAI,EACJ,KAAK,EACL,OAAO,QAAQ,KAAK,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,MAAM,EAAE,QAAQ,CAAC,CAClF,CACF,CAAC;IACJ,CAAC;IAgHM,KAAK,CAAC,2BAA2B,CACtC,KAAsC,EACtC,WAAmB,EACnB,UAA2C,EAAE;QAE7C,OAAO,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAC3B,oDAAoD,EACpD,OAAO,EACP,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,EAAE,KAAK,EAAE,MAAM,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC,CAC3D,CAAC;IACJ,CAAC;IAED;;;;;;;OAOG;IACK,OAAO,CACb,KAAsC,EACtC,KAAqB,EACrB,OAAwC;QAExC,MAAM,EACJ,OAAO,EAAE,cAAc,EACvB,UAAU,EAAE,iBAAiB,EAC7B,eAAe,GAChB,GAAG,OAAO,KAAK,KAAK,QAAQ;YAC3B,CAAC,CAAC,EAAE,OAAO,EAAE,KAAK,EAAE,UAAU,EAAE,SAAS,EAAE,eAAe,EAAE,CAAC,CAAgB,EAAE,EAAE,CAAC,CAAC,EAAE;YACrF,CAAC,CAAC,KAAK,CAAC;QAEV,IAAI,iBAAiB,IAAI,iBAAiB,KAAK,2BAA2B,EAAE;YAC1E,MAAM,IAAI,KAAK,CACb;gBACE,2DAA2D,iBAAiB,GAAG;gBAC/E,2BAA2B,2BAA2B,GAAG;gBACzD,mEAAmE;aACpE,CAAC,IAAI,CAAC,GAAG,CAAC,CACZ,CAAC;SACH;QAED,OAAO,IAAI,CAAC,mBAAmB,CAC7B,CAAC,WAAW,EAAE,EAAE;YACd,MAAM,CAAC,WAAW,EAAE,cAAc,CAAC,GAAG,gBAAgB,CAAC,KAAK,CAAC,CAAC;YAE9D,OAAO,IAAI,CAAC,WAAW,CAAC,cAAc,CAAC,eAAe,CAAC,cAAc,EAAE,WAAkB,kCACpF,OAAO,KACV,WAAW;gBACX,cAAc,IACd,CAAC;QACL,CAAC,EACD;YACE,cAAc;YACd,OAAO;YACP,eAAe,EAAE,CAAC,MAAM,EAAE,EAAE,CAAC,eAAe,CAAC,4BAA4B,CAAC,MAAM,CAAC,CAAC;SACnF,CACF,CAAC;IACJ,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OAqCG;IACI,KAAK,CAAC,qBAAqB,CAChC,YAAoB,EACpB,QAAmC;IACnC,8DAA8D;IAC9D,UAAmC,EAAE;QAErC,OAAO,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAC3B,8CAA8C,EAC9C,OAAO,EACP,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,IAAI,EAAE,YAAY,EAAE,MAAM,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC,CACjE,CAAC;IACJ,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OAqCG;IACI,KAAK,CAAC,4BAA4B,CACvC,YAAoB,EACpB,WAAmB;IACnB,8DAA8D;IAC9D,UAAmC,EAAE;QAErC,OAAO,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAC3B,qDAAqD,EACrD,OAAO,EACP,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,IAAI,EAAE,YAAY,EAAE,MAAM,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC,CACnE,CAAC;IACJ,CAAC;IAED;;;;;;OAMG;IACK,QAAQ,CACd,YAAoB,EACpB,KAAqB,EACrB,OAAgC;QAEhC,OAAO,IAAI,CAAC,mBAAmB,CAC7B,KAAK,EAAE,WAAW,EAAE,EAAE;YACpB,MAAM,CAAC,WAAW,EAAE,eAAe,CAAC,GAAG,gBAAgB,CAAC,KAAK,CAAC,CAAC;YAE/D,OAAO,IAAI,CAAC,WAAW,CAAC,mBAAmB,CAAC,gBAAgB,CAC1D,YAAY,EACZ,WAAkB,kCAEb,OAAO,KACV,WAAW;gBACX,eAAe,IAElB,CAAC;QACJ,CAAC,EACD;YACE,cAAc,EAAE,YAAY;YAC5B,OAAO;YACP,eAAe,EAAE,4BAA4B;SAC9C,CACF,CAAC;IACJ,CAAC;IAED;;;;;;;;OAQG;IACK,KAAK,CAAC,mBAAmB,CAC/B,cAE4C,EAC5C,UAA+C;QAE/C,MAAM,EAAE,UAAU,EAAE,GAAG,UAAU,CAAC,OAAO,CAAC;QAE1C,kFAAkF;QAClF,+CAA+C;QAE/C,MAAM,gBAAgB,GAAG,CACvB,GAAqB,EACrB,iBAAyB,EACQ,EAAE,CACnC,IAAI,CAAC,QAAQ,CAAC,QAAQ,CACpB,8DAA8D,EAC9D,UAAU,CAAC,OAAO,EAClB,CAAC,YAAY,EAAE,EAAE,CACf,IAAI,CAAC,WAAW,CAAC,oBAAoB,CACnC;YACE,OAAO,gCACL,UAAU,EAAE,KAAK,EAAE,WAAW,EAAE,GAAG,IAAI,EAAE,EAAE;;oBACzC,mDAAmD;oBACnD,MAAM,gBAAgB,GAAG,WAAW,CAAC,OAAO,CAAC,GAAG,CAAC,aAAa,CAAC,CAAC;oBAChE,oGAAoG;oBACpG,QAAQ;oBACR,IAAI,gBAAgB,EAAE;wBACpB,MAAM,YAAY,GAAG,MAAM,CAAC,gBAAgB,CAAC,GAAG,IAAI,CAAC;wBACrD,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,YAAY,CAAC,EAAE;4BAC/B,GAAG,CAAC,WAAW,CAAC,YAAY,CAAC,CAAC;yBAC/B;6BAAM;4BACL,GAAG,CAAC,WAAW,CAAC,IAAI,CAAC,KAAK,CAAC,gBAAgB,CAAC,GAAG,IAAI,CAAC,GAAG,EAAE,CAAC,CAAC;yBAC5D;qBACF;yBAAM;wBACL,GAAG,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;qBAC5B;oBAED,wDAAwD;oBACxD,OAAO,MAAA,YAAY,CAAC,UAAU,6DAAG,WAAW,EAAE,GAAG,IAAI,CAAC,CAAC;gBACzD,CAAC,IACE,YAAY;gBACf,uGAAuG;gBACvG,2EAA2E;gBAC3E,WAAW,EAAE,GAAG,CAAC,WAAW,GAC7B;SACF,EACD;YACE,IAAI,EAAE,iBAAiB;YACvB,UAAU,EAAE,KAAK;YACjB,SAAS,EAAE;gBACT,GAAG,EAAE;oBACH,UAAU,EAAE,OAAO,CAAC,sBAAsB;iBAC3C;gBACD,OAAO,EAAE;oBACP,UAAU,EAAE,OAAO,CAAC,aAAa;iBAClC;aACF;YACD,6DAA6D;YAC7D,gBAAgB,EAAE,CAAC,OAAO,CAAC;YAC3B,UAAU,EAAE,UAAU;SACvB,CACF,CACJ,CAAC;QAEJ,MAAM,MAAM;QACV,0DAA0D;QAC1D,UAAU,KAAK,SAAS;YACtB,CAAC,CAAC,KAAK,EAAE,GAAqB,EAAE,EAAE,CAC9B,IAAI,CAAC,QAAQ,CAAC,QAAQ,CACpB,oDAAoD,EACpD,UAAU,CAAC,OAAO,EAClB,KAAK,IAAI,EAAE;gBACT,MAAM,EAAE,aAAa,EAAE,iBAAiB,EAAE,OAAO,EAAE,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAI1E,CAAC;gBAEF,IAAI,CAAC,aAAa,IAAI,aAAa,KAAK,WAAW,EAAE;oBACnD,MAAM,IAAI,KAAK,CACb;wBACE,sFAAsF;wBACtF,0BAA0B,aAAa,gBAAgB,WAAW,KAAK;qBACxE,CAAC,IAAI,CAAC,GAAG,CAAC,CACZ,CAAC;iBACH;gBAED,MAAM,MAAM,GAAG,MAAM,gBAAgB,CAAC,GAAG,EAAE,iBAAiB,CAAC,CAAC;gBAE9D,OAAO,oCAAoC,CACzC,UAAU,EACV,OAAO,EACP,iBAAiB,EACjB,MAAM,CACP,CAAC;YACJ,CAAC,CACF;YACL,CAAC,CAAC,iEAAiE;gBACjE,KAAK,EAAE,GAAqB,EAAE,EAAE,CAC9B,IAAI,CAAC,QAAQ,CAAC,QAAQ,CACpB,mDAAmD,EACnD,UAAU,CAAC,OAAO,EAClB,KAAK,IAAI,EAAE;oBACT,MAAM,EAAE,iBAAiB,EAAE,GAAG,MAAM,cAAc,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC;oBAEpE,IAAI,iBAAiB,KAAK,SAAS,EAAE;wBACnC,MAAM,IAAI,KAAK,CACb,qEAAqE,CACtE,CAAC;qBACH;oBAED,MAAM,MAAM,GAAG,MAAM,gBAAgB,CAAC,GAAG,EAAE,iBAAiB,CAAC,CAAC;oBAE9D,OAAO,oCAAoC,CACzC,UAAU,EACV,UAAU,CAAC,cAAc,EACzB,iBAAiB,EACjB,MAAM,CACP,CAAC;gBACJ,CAAC,CACF,CAAC;QAEV,MAAM,MAAM,GAAG,MAAM,GAAG,CACtB;YACE,IAAI,EAAE,MAAM;YACZ,IAAI,EAAE,KAAK,EAAE,GAAG,EAAE,EAAE,iBAAiB,EAAE,OAAO,EAAE,EAAE,EAAE,CAClD,IAAI,CAAC,QAAQ,CAAC,QAAQ,CACpB,kDAAkD,EAClD,EAAE,EACF,KAAK,IAAI,EAAE;gBACT,MAAM,MAAM,GAAG,MAAM,gBAAgB,CAAC,GAAG,EAAE,iBAAiB,CAAC,CAAC;gBAE9D,OAAO,oCAAoC,CACzC,UAAU,EACV,OAAO,EACP,iBAAiB,EACjB,MAAM,CACP,CAAC;YACJ,CAAC,CACF;YACH,SAAS,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAE,EAAE,EAAE,CAC5C,IAAI,CAAC,SAAS,CAAC,EAAE,aAAa,EAAE,WAAW,EAAE,EAAE,EAAE,OAAO,EAAE,iBAAiB,EAAE,CAAC;SACjF,EACD,UAAU,CAAC,OAAO,CAAC,kBAAkB,EACrC,UAAU,CAAC,OAAO,CAAC,WAAW,CAC/B,CAAC;QAEF,IAAI,UAAU,CAAC,OAAO,CAAC,UAAU,KAAK,SAAS,EAAE;YAC/C,MAAM,CAAC,UAAU,CAAC,UAAU,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;YACjD,UAAU,CAAC,OAAO,CAAC,UAAU,CAAC,MAAM,CAAC,iBAAiB,EAAE,CAAC,CAAC;SAC3D;QAED,OAAO,MAAM,CAAC;IAChB,CAAC;CAGF;AAED;;;GAGG;AACH,SAAS,gBAAgB,CACvB,KAAqB;IAErB,QAAQ,KAAK,CAAC,IAAI,EAAE;QAClB,KAAK,MAAM;YACT,OAAO,CAAC,0BAA0B,EAAE,KAAK,CAAC,IAAI,CAAC,CAAC;QAClD,KAAK,KAAK;YACR,OAAO,CAAC,kBAAkB,EAAE,EAAE,SAAS,EAAE,KAAK,CAAC,GAAG,EAAE,CAAC,CAAC;QACxD,KAAK,QAAQ;YACX,OAAO,CAAC,kBAAkB,EAAE,EAAE,YAAY,EAAE,KAAK,CAAC,MAAM,EAAE,CAAC,CAAC;QAC9D,OAAO,CAAC,CAAC;YACP,MAAM,SAAS,GAAU,KAAK,CAAC;YAC/B,MAAM,IAAI,KAAK,CAAC,wCAAwC,SAAS,EAAE,CAAC,CAAC;SACtE;KACF;AACH,CAAC;AAED;;GAEG;AACH,uFAAuF;AAEvF,SAAS,MAAM,CACb,IAAO,EACP,KAA2F;IAE3F,OAAO;QACL,IAAI;QACJ,CAAC,IAAI,CAAC,EAAE,KAAK;KACe,CAAC;AACjC,CAAC","sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n\nimport { KeyCredential, TokenCredential } from \"@azure/core-auth\";\nimport { createTracingClient } from \"@azure/core-tracing\";\nimport { TracingClient } from \"@azure/core-tracing\";\nimport { FORM_RECOGNIZER_API_VERSION, SDK_VERSION } from \"./constants\";\nimport {\n  AnalyzeDocumentRequest,\n  AnalyzeResultOperation,\n  ContentType,\n  GeneratedClient,\n} from \"./generated\";\nimport { accept1 } from \"./generated/models/parameters\";\nimport {\n  AnalysisOperationDefinition,\n  AnalysisPoller,\n  AnalyzeResult,\n  DocumentAnalysisPollOperationState,\n  FormRecognizerRequestBody,\n  toAnalyzeResultFromGenerated,\n  toDocumentAnalysisPollOperationState,\n} from \"./lro/analysis\";\nimport { OperationContext, lro } from \"./lro/util/poller\";\nimport { AnalyzeDocumentOptions } from \"./options/AnalyzeDocumentOptions\";\nimport { DocumentAnalysisClientOptions } from \"./options/FormRecognizerClientOptions\";\nimport { DocumentModel } from \"./documentModel\";\nimport { makeServiceClient, Mappers, SERIALIZER } from \"./util\";\nimport { AbortSignalLike } from \"@azure/abort-controller\";\nimport { ClassifyDocumentOptions } from \"./options/ClassifyDocumentOptions\";\n\n/**\n * A client for interacting with the Form Recognizer service's analysis features.\n *\n * ### Examples:\n *\n * The Form Recognizer service and clients support two means of authentication:\n *\n * #### Azure Active Directory\n *\n * ```javascript\n * import { DocumentAnalysisClient } from \"@azure/ai-form-recognizer\";\n * import { DefaultAzureCredential } from \"@azure/identity\";\n *\n * const endpoint = \"https://<resource name>.cognitiveservices.azure.com\";\n * const credential = new DefaultAzureCredential();\n *\n * const client = new DocumentAnalysisClient(endpoint, credential);\n * ```\n *\n * #### API Key (Subscription Key)\n *\n * ```javascript\n * import { DocumentAnalysisClient, AzureKeyCredential } from \"@azure/ai-form-recognizer\";\n *\n * const endpoint = \"https://<resource name>.cognitiveservices.azure.com\";\n * const credential = new AzureKeyCredential(\"<api key>\");\n *\n * const client = new DocumentAnalysisClient(endpoint, credential);\n * ```\n */\nexport class DocumentAnalysisClient {\n  private _restClient: GeneratedClient;\n  private _tracing: TracingClient;\n\n  /**\n   * Create a `DocumentAnalysisClient` instance from a resource endpoint and a an Azure Identity `TokenCredential`.\n   *\n   * See the [`@azure/identity`](https://npmjs.com/package/\\@azure/identity) package for more information about\n   * authenticating with Azure Active Directory.\n   *\n   * ### Example:\n   *\n   * ```javascript\n   * import { DocumentAnalysisClient } from \"@azure/ai-form-recognizer\";\n   * import { DefaultAzureCredential } from \"@azure/identity\";\n   *\n   * const endpoint = \"https://<resource name>.cognitiveservices.azure.com\";\n   * const credential = new DefaultAzureCredential();\n   *\n   * const client = new DocumentAnalysisClient(endpoint, credential);\n   * ```\n   *\n   * @param endpoint - the endpoint URL of an Azure Cognitive Services instance\n   * @param credential - a TokenCredential instance from the `@azure/identity` package\n   * @param options - optional settings for configuring all methods in the client\n   */\n  public constructor(\n    endpoint: string,\n    credential: TokenCredential,\n    options?: DocumentAnalysisClientOptions\n  );\n  /**\n   * Create a `DocumentAnalysisClient` instance from a resource endpoint and a static API key (`KeyCredential`),\n   *\n   * ### Example:\n   *\n   * ```javascript\n   * import { DocumentAnalysisClient, AzureKeyCredential } from \"@azure/ai-form-recognizer\";\n   *\n   * const endpoint = \"https://<resource name>.cognitiveservices.azure.com\";\n   * const credential = new AzureKeyCredential(\"<api key>\");\n   *\n   * const client = new DocumentAnalysisClient(endpoint, credential);\n   * ```\n   *\n   * @param endpoint - the endpoint URL of an Azure Cognitive Services instance\n   * @param credential - a KeyCredential containing the Cognitive Services instance subscription key\n   * @param options - optional settings for configuring all methods in the client\n   */\n  public constructor(\n    endpoint: string,\n    credential: KeyCredential,\n    options?: DocumentAnalysisClientOptions\n  );\n  /**\n   * @hidden\n   */\n  public constructor(\n    endpoint: string,\n    credential: KeyCredential | TokenCredential,\n    options?: DocumentAnalysisClientOptions\n  );\n  public constructor(\n    endpoint: string,\n    credential: KeyCredential | TokenCredential,\n    options: DocumentAnalysisClientOptions = {}\n  ) {\n    this._restClient = makeServiceClient(endpoint, credential, options);\n    this._tracing = createTracingClient({\n      packageName: \"@azure/ai-form-recognizer\",\n      packageVersion: SDK_VERSION,\n      namespace: \"Microsoft.CognitiveServices\",\n    });\n  }\n\n  // #region Analysis\n\n  /**\n   * Extract data from an input using a model given by its unique ID.\n   *\n   * This operation supports custom as well as prebuilt models. For example, to use the prebuilt invoice model, provide\n   * the model ID \"prebuilt-invoice\", or to use the simpler prebuilt layout model, provide the model ID\n   * \"prebuilt-layout\".\n   *\n   * The fields produced in the `AnalyzeResult` depend on the model that is used for analysis, and the values in any\n   * extracted documents' fields depend on the document types in the model (if any) and their corresponding field\n   * schemas.\n   *\n   * ### Examples\n   *\n   * This method supports streamable request bodies ({@link FormRecognizerRequestBody}) such as Node.JS `ReadableStream`\n   * objects, browser `Blob`s, and `ArrayBuffer`s. The contents of the body will be uploaded to the service for analysis.\n   *\n   * ```javascript\n   * import * as fs from \"fs\";\n   *\n   * const file = fs.createReadStream(\"path/to/receipt.pdf\");\n   *\n   * // The model that is passed to the following function call determines the type of the eventual result. In the\n   * // example, we will use the prebuilt receipt model, but you could use a custom model ID/name instead.\n   * const poller = await client.beginAnalyzeDocument(\"prebuilt-receipt\", file);\n   *\n   * // The result is a long-running operation (poller), which must itself be polled until the operation completes\n   * const {\n   *   pages, // pages extracted from the document, which contain lines and words\n   *   tables, // extracted tables, organized into cells that contain their contents\n   *   styles, // text styles (ex. handwriting) that were observed in the document\n   *   keyValuePairs, // extracted pairs of elements  (directed associations from one element in the input to another)\n   *   entities, // extracted entities in the input's content, which are categorized (ex. \"Location\" or \"Organization\")\n   *   documents // extracted documents (instances of one of the model's document types and its field schema)\n   * } = await poller.pollUntilDone();\n   *\n   * // Extract the fields of the first document. These fields constitute a receipt, because we used the receipt model\n   * const [{ fields: receipt }] = documents;\n   *\n   * // The fields correspond to the model's document types and their field schemas. Refer to the Form Recognizer\n   * // documentation for information about the document types and field schemas within a model, or use the `getModel`\n   * // operation to view this information programmatically.\n   * console.log(\"The type of this receipt is:\", receipt?.[\"ReceiptType\"]?.value);\n   * ```\n   *\n   *\n   * @param modelId - the unique ID (name) of the model within this client's resource\n   * @param document - a {@link FormRecognizerRequestBody} that will be uploaded with the request\n   * @param options - optional settings for the analysis operation and poller\n   * @returns a long-running operation (poller) that will eventually produce an `AnalyzeResult`\n   */\n  public async beginAnalyzeDocument(\n    modelId: string,\n    document: FormRecognizerRequestBody,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options?: AnalyzeDocumentOptions\n  ): Promise<AnalysisPoller>;\n  /**\n   * Extract data from an input using a model that has a known, strongly-typed document schema (a {@link DocumentModel}).\n   *\n   * The fields produced in the `AnalyzeResult` depend on the model that is used for analysis. In TypeScript, the type\n   * of the result for this method overload is inferred from the type of the input `DocumentModel`.\n   *\n   * ### Examples\n   *\n   * This method supports streamable request bodies ({@link FormRecognizerRequestBody}) such as Node.JS `ReadableStream`\n   * objects, browser `Blob`s, and `ArrayBuffer`s. The contents of the body will be uploaded to the service for analysis.\n   *\n   * If the input provided is a string, it will be treated as a URL to the location of a document to be analyzed. See the\n   * {@link beginAnalyzeDocumentFromUrl} method for more information. Use of that method is preferred when using URLs,\n   * and URL support is only provided in this method for backwards compatibility.\n   *\n   * ```typescript\n   * import * as fs from \"fs\";\n   *\n   * // See the `prebuilt` folder in the SDK samples (http://aka.ms/azsdk/formrecognizer/js/samples) for examples of\n   * // DocumentModels for known prebuilts.\n   * import { PrebuiltReceiptModel } from \"./prebuilt-receipt.ts\";\n   *\n   * const file = fs.createReadStream(\"path/to/receipt.pdf\");\n   *\n   * // The model that is passed to the following function call determines the type of the eventual result. In the\n   * // example, we will use the prebuilt receipt model.\n   * const poller = await client.beginAnalyzeDocument(PrebuiltReceiptModel, file);\n   *\n   * // The result is a long-running operation (poller), which must itself be polled until the operation completes\n   * const {\n   *   pages, // pages extracted from the document, which contain lines and words\n   *   tables, // extracted tables, organized into cells that contain their contents\n   *   styles, // text styles (ex. handwriting) that were observed in the document\n   *   keyValuePairs, // extracted pairs of elements  (directed associations from one element in the input to another)\n   *\n   *   documents // extracted documents (instances of one of the model's document types and its field schema)\n   * } = await poller.pollUntilDone();\n   *\n   * // Extract the fields of the first document. These fields constitute a receipt, because we used the receipt model\n   * const [{ fields: receipt }] = documents;\n   *\n   * // Since we used the strongly-typed PrebuiltReceiptModel object instead of the \"prebuilt-receipt\" model ID\n   * // string, the fields of the receipt are strongly-typed and have camelCase names (as opposed to PascalCase).\n   * console.log(\"The type of this receipt is:\", receipt.receiptType?.value);\n   * ```\n   *\n   * @param model - a {@link DocumentModel} representing the model to use for analysis and the expected output type\n   * @param document - a {@link FormRecognizerRequestBody} that will be uploaded with the request\n   * @param options - optional settings for the analysis operation and poller\n   * @returns a long-running operation (poller) that will eventually produce an `AnalyzeResult` with documents that have\n   *          the result type associated with the input model\n   */\n  public async beginAnalyzeDocument<Result>(\n    model: DocumentModel<Result>,\n    document: FormRecognizerRequestBody,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options?: AnalyzeDocumentOptions<Result>\n  ): Promise<AnalysisPoller<Result>>;\n  public async beginAnalyzeDocument(\n    model: string | DocumentModel<unknown>,\n    document: FormRecognizerRequestBody,\n    options: AnalyzeDocumentOptions<unknown> = {}\n  ): Promise<AnalysisPoller<unknown>> {\n    return this._tracing.withSpan(\n      \"DocumentAnalysisClient.beginAnalyzeDocument\",\n      options,\n      // In the first version of the SDK, the document input was treated as a URL if it was a string, and we preserve\n      // this behavior to avoid introducing a breaking change.\n      this.analyze.bind(\n        this,\n        model,\n        typeof document === \"string\" ? source(\"url\", document) : source(\"body\", document)\n      )\n    );\n  }\n\n  /**\n   * Extract data from an input using a model given by its unique ID.\n   *\n   * This operation supports custom as well as prebuilt models. For example, to use the prebuilt invoice model, provide\n   * the model ID \"prebuilt-invoice\", or to use the simpler prebuilt layout model, provide the model ID\n   * \"prebuilt-layout\".\n   *\n   * The fields produced in the `AnalyzeResult` depend on the model that is used for analysis, and the values in any\n   * extracted documents' fields depend on the document types in the model (if any) and their corresponding field\n   * schemas.\n   *\n   * ### Examples\n   *\n   * This method supports extracting data from a file at a given URL. The Form Recognizer service will attempt to\n   * download a file using the submitted URL, so the URL must be accessible from the public internet. For example, a SAS\n   * token can be used to grant read access to a blob in Azure Storage, and the service will use the SAS-encoded URL to\n   * request the file.\n   *\n   * ```javascript\n   * // the URL must be publicly accessible\n   * const url = \"<receipt document url>\";\n   *\n   * // The model that is passed to the following function call determines the type of the eventual result. In the\n   * // example, we will use the prebuilt receipt model, but you could use a custom model ID/name instead.\n   * const poller = await client.beginAnalyzeDocument(\"prebuilt-receipt\", url);\n   *\n   * // The result is a long-running operation (poller), which must itself be polled until the operation completes\n   * const {\n   *   pages, // pages extracted from the document, which contain lines and words\n   *   tables, // extracted tables, organized into cells that contain their contents\n   *   styles, // text styles (ex. handwriting) that were observed in the document\n   *   keyValuePairs, // extracted pairs of elements  (directed associations from one element in the input to another)\n   *\n   *   documents // extracted documents (instances of one of the model's document types and its field schema)\n   * } = await poller.pollUntilDone();\n   *\n   * // Extract the fields of the first document. These fields constitute a receipt, because we used the receipt model\n   * const [{ fields: receipt }] = documents;\n   *\n   * // The fields correspond to the model's document types and their field schemas. Refer to the Form Recognizer\n   * // documentation for information about the document types and field schemas within a model, or use the `getModel`\n   * // operation to view this information programmatically.\n   * console.log(\"The type of this receipt is:\", receipt?.[\"ReceiptType\"]?.value);\n   * ```\n   *\n   * @param modelId - the unique ID (name) of the model within this client's resource\n   * @param documentUrl - a URL (string) to an input document accessible from the public internet\n   * @param options - optional settings for the analysis operation and poller\n   * @returns a long-running operation (poller) that will eventually produce an `AnalyzeResult`\n   */\n  public async beginAnalyzeDocumentFromUrl(\n    modelId: string,\n    documentUrl: string,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options?: AnalyzeDocumentOptions\n  ): Promise<AnalysisPoller>;\n  /**\n   * Extract data from an input using a model that has a known, strongly-typed document schema (a {@link DocumentModel}).\n   *\n   * The fields produced in the `AnalyzeResult` depend on the model that is used for analysis. In TypeScript, the type\n   * of the result for this method overload is inferred from the type of the input `DocumentModel`.\n   *\n   * ### Examples\n   *\n   * This method supports extracting data from a file at a given URL. The Form Recognizer service will attempt to\n   * download a file using the submitted URL, so the URL must be accessible from the public internet. For example, a SAS\n   * token can be used to grant read access to a blob in Azure Storage, and the service will use the SAS-encoded URL to\n   * request the file.\n   *\n   * ```typescript\n   * // See the `prebuilt` folder in the SDK samples (http://aka.ms/azsdk/formrecognizer/js/samples) for examples of\n   * // DocumentModels for known prebuilts.\n   * import { PrebuiltReceiptModel } from \"./prebuilt-receipt.ts\";\n   *\n   * // the URL must be publicly accessible\n   * const url = \"<receipt document url>\";\n   *\n   * // The model that is passed to the following function call determines the type of the eventual result. In the\n   * // example, we will use the prebuilt receipt model.\n   * const poller = await client.beginAnalyzeDocument(PrebuiltReceiptModel, url);\n   *\n   * // The result is a long-running operation (poller), which must itself be polled until the operation completes\n   * const {\n   *   pages, // pages extracted from the document, which contain lines and words\n   *   tables, // extracted tables, organized into cells that contain their contents\n   *   styles, // text styles (ex. handwriting) that were observed in the document\n   *   keyValuePairs, // extracted pairs of elements  (directed associations from one element in the input to another)\n   *\n   *   documents // extracted documents (instances of one of the model's document types and its field schema)\n   * } = await poller.pollUntilDone();\n   *\n   * // Extract the fields of the first document. These fields constitute a receipt, because we used the receipt model\n   * const [{ fields: receipt }] = documents;\n   *\n   * // Since we used the strongly-typed PrebuiltReceiptModel object instead of the \"prebuilt-receipt\" model ID\n   * // string, the fields of the receipt are strongly-typed and have camelCase names (as opposed to PascalCase).\n   * console.log(\"The type of this receipt is:\", receipt.receiptType?.value);\n   * ```\n   *\n   * @param model - a {@link DocumentModel} representing the model to use for analysis and the expected output type\n   * @param documentUrl - a URL (string) to an input document accessible from the public internet\n   * @param options - optional settings for the analysis operation and poller\n   * @returns a long-running operation (poller) that will eventually produce an `AnalyzeResult`\n   */\n  public async beginAnalyzeDocumentFromUrl<Result>(\n    model: DocumentModel<Result>,\n    documentUrl: string,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options?: AnalyzeDocumentOptions<Result>\n  ): Promise<AnalysisPoller<Result>>;\n  public async beginAnalyzeDocumentFromUrl(\n    model: string | DocumentModel<unknown>,\n    documentUrl: string,\n    options: AnalyzeDocumentOptions<unknown> = {}\n  ): Promise<AnalysisPoller<unknown>> {\n    return this._tracing.withSpan(\n      \"DocumentAnalysisClient.beginAnalyzeDocumentFromUrl\",\n      options,\n      this.analyze.bind(this, model, source(\"url\", documentUrl))\n    );\n  }\n\n  /**\n   * A helper method for running analysis polymorphically.\n   *\n   * @param model - the model ID or DocumentModel to use for analysis\n   * @param input - the string URL or request body to use\n   * @param options - analysis options\n   * @returns - an analysis poller\n   */\n  private analyze(\n    model: string | DocumentModel<unknown>,\n    input: DocumentSource,\n    options: AnalyzeDocumentOptions<unknown>\n  ) {\n    const {\n      modelId: initialModelId,\n      apiVersion: requestApiVersion,\n      transformResult,\n    } = typeof model === \"string\"\n      ? { modelId: model, apiVersion: undefined, transformResult: (v: AnalyzeResult) => v }\n      : model;\n\n    if (requestApiVersion && requestApiVersion !== FORM_RECOGNIZER_API_VERSION) {\n      throw new Error(\n        [\n          `API Version mismatch: the provided model wants version: ${requestApiVersion},`,\n          `but the client is using ${FORM_RECOGNIZER_API_VERSION}.`,\n          \"The API version of the model must match the client's API version.\",\n        ].join(\" \")\n      );\n    }\n\n    return this.createUnifiedPoller<unknown>(\n      (abortSignal) => {\n        const [contentType, analyzeRequest] = toAnalyzeRequest(input);\n\n        return this._restClient.documentModels.analyzeDocument(initialModelId, contentType as any, {\n          ...options,\n          abortSignal,\n          analyzeRequest,\n        });\n      },\n      {\n        initialModelId,\n        options,\n        transformResult: (result) => transformResult(toAnalyzeResultFromGenerated(result)),\n      }\n    );\n  }\n\n  /**\n   * Classify a document using a custom classifier given by its ID.\n   *\n   * This method produces a long-running operation (poller) that will eventually produce an `AnalyzeResult`. This is the\n   * same type as `beginAnalyzeDocument` and `beginAnalyzeDocumentFromUrl`, but the result will only contain a small\n   * subset of its fields. Only the `documents` field and `pages` field will be populated, and only minimal page\n   * information will be returned. The `documents` field will contain information about all the identified documents and\n   * the `docType` that they were classified as.\n   *\n   * ### Example\n   *\n   * This method supports streamable request bodies ({@link FormRecognizerRequestBody}) such as Node.JS `ReadableStream`\n   * objects, browser `Blob`s, and `ArrayBuffer`s. The contents of the body will be uploaded to the service for analysis.\n   *\n   * ```typescript\n   * import * as fs from \"fs\";\n   *\n   * const file = fs.createReadStream(\"path/to/file.pdf\");\n   *\n   * const poller = await client.beginClassifyDocument(\"<classifier ID>\", file);\n   *\n   * // The result is a long-running operation (poller), which must itself be polled until the operation completes\n   * const {\n   *   pages, // pages extracted from the document, which contain only basic information for classifiers\n   *   documents // extracted documents and their types\n   * } = await poller.pollUntilDone();\n   *\n   * // We'll print the documents and their types\n   * for (const { docType } of documents) {\n   *   console.log(\"The type of this document is:\", docType);\n   * }\n   * ```\n   *\n   * @param classifierId - the ID of the custom classifier to use for analysis\n   * @param document - the document to classify\n   * @param options - options for the classification operation\n   * @returns a long-running operation (poller) that will eventually produce an `AnalyzeResult`\n   */\n  public async beginClassifyDocument(\n    classifierId: string,\n    document: FormRecognizerRequestBody,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options: ClassifyDocumentOptions = {}\n  ): Promise<AnalysisPoller> {\n    return this._tracing.withSpan(\n      \"DocumentAnalysisClient.beginClassifyDocument\",\n      options,\n      this.classify.bind(this, classifierId, source(\"body\", document))\n    );\n  }\n\n  /**\n   * Classify a document from a URL using a custom classifier given by its ID.\n   *\n   * This method produces a long-running operation (poller) that will eventually produce an `AnalyzeResult`. This is the\n   * same type as `beginAnalyzeDocument` and `beginAnalyzeDocumentFromUrl`, but the result will only contain a small\n   * subset of its fields. Only the `documents` field and `pages` field will be populated, and only minimal page\n   * information will be returned. The `documents` field will contain information about all the identified documents and\n   * the `docType` that they were classified as.\n   *\n   * ### Example\n   *\n   * This method supports extracting data from a file at a given URL. The Form Recognizer service will attempt to\n   * download a file using the submitted URL, so the URL must be accessible from the public internet. For example, a SAS\n   * token can be used to grant read access to a blob in Azure Storage, and the service will use the SAS-encoded URL to\n   * request the file.\n   *\n   * ```typescript\n   * // the URL must be publicly accessible\n   * const url = \"<file url>\";\n   *\n   * const poller = await client.beginClassifyDocument(\"<classifier ID>\", url);\n   *\n   * // The result is a long-running operation (poller), which must itself be polled until the operation completes\n   * const {\n   *   pages, // pages extracted from the document, which contain only basic information for classifiers\n   *   documents // extracted documents and their types\n   * } = await poller.pollUntilDone();\n   *\n   * // We'll print the documents and their types\n   * for (const { docType } of documents) {\n   *   console.log(\"The type of this document is:\", docType);\n   * }\n   * ```\n   * @param classifierId - the ID of the custom classifier to use for analysis\n   * @param documentUrl - the URL of the document to classify\n   * @param options -\n   * @returns\n   */\n  public async beginClassifyDocumentFromUrl(\n    classifierId: string,\n    documentUrl: string,\n    // eslint-disable-next-line @azure/azure-sdk/ts-naming-options\n    options: ClassifyDocumentOptions = {}\n  ): Promise<AnalysisPoller> {\n    return this._tracing.withSpan(\n      \"DocumentAnalysisClient.beginClassifyDocumentFromUrl\",\n      options,\n      this.classify.bind(this, classifierId, source(\"url\", documentUrl))\n    );\n  }\n\n  /**\n   * A helper method for running classification polymorphically.\n   * @param classifierId - the ID of the classifier to use\n   * @param input - the string URL or request body to use\n   * @param options - analysis options\n   * @returns an analysis poller\n   */\n  private classify(\n    classifierId: string,\n    input: DocumentSource,\n    options: ClassifyDocumentOptions\n  ): Promise<AnalysisPoller> {\n    return this.createUnifiedPoller(\n      async (abortSignal) => {\n        const [contentType, classifyRequest] = toAnalyzeRequest(input);\n\n        return this._restClient.documentClassifiers.classifyDocument(\n          classifierId,\n          contentType as any,\n          {\n            ...options,\n            abortSignal,\n            classifyRequest,\n          }\n        );\n      },\n      {\n        initialModelId: classifierId,\n        options,\n        transformResult: toAnalyzeResultFromGenerated,\n      }\n    );\n  }\n\n  /**\n   * Create an LRO poller that handles analysis operations.\n   *\n   * This is the meat of all analysis polling operations.\n   *\n   * @param startOperation - function that starts the operation and returns the operation location\n   * @param definition - operation definition (initial model ID, operation transforms, request options)\n   * @returns - an analysis poller that produces the given return types according to the operation spec\n   */\n  private async createUnifiedPoller<Result>(\n    startOperation: (\n      abortSignal: AbortSignalLike | undefined\n    ) => Promise<{ operationLocation?: string }>,\n    definition: AnalysisOperationDefinition<Result>\n  ): Promise<AnalysisPoller<Result>> {\n    const { resumeFrom } = definition.options;\n\n    // TODO: what should we do if resumeFrom.modelId is different from initialModelId?\n    // And what do we do with the redundant input??\n\n    const getAnalyzeResult = (\n      ctx: OperationContext,\n      operationLocation: string\n    ): Promise<AnalyzeResultOperation> =>\n      this._tracing.withSpan(\n        \"DocumentAnalysisClient.createAnalysisPoller-getAnalyzeResult\",\n        definition.options,\n        (finalOptions) =>\n          this._restClient.sendOperationRequest<AnalyzeResultOperation>(\n            {\n              options: {\n                onResponse: async (rawResponse, ...args) => {\n                  // Capture the `Retry-After` header if it was sent.\n                  const retryAfterHeader = rawResponse.headers.get(\"retry-after\");\n                  // Convert the header value to milliseconds. If the header is not a valid number, then it is an HTTP\n                  // date.\n                  if (retryAfterHeader) {\n                    const retryAfterMs = Number(retryAfterHeader) * 1000;\n                    if (!Number.isNaN(retryAfterMs)) {\n                      ctx.updateDelay(retryAfterMs);\n                    } else {\n                      ctx.updateDelay(Date.parse(retryAfterHeader) - Date.now());\n                    }\n                  } else {\n                    ctx.updateDelay(undefined);\n                  }\n\n                  // Forward the `onResponse` callback if it was provided.\n                  return finalOptions.onResponse?.(rawResponse, ...args);\n                },\n                ...finalOptions,\n                // We need to pass the abort signal from the context rather than from the options, since the user could\n                // poll the LRO with a different AbortSignal than it was instantiated with.\n                abortSignal: ctx.abortSignal,\n              },\n            },\n            {\n              path: operationLocation,\n              httpMethod: \"GET\",\n              responses: {\n                200: {\n                  bodyMapper: Mappers.AnalyzeResultOperation,\n                },\n                default: {\n                  bodyMapper: Mappers.ErrorResponse,\n                },\n              },\n              // URL is fully-formed, so we don't need any query parameters\n              headerParameters: [accept1],\n              serializer: SERIALIZER,\n            }\n          )\n      );\n\n    const toInit =\n      // If the user gave us a stored token, we'll poll it again\n      resumeFrom !== undefined\n        ? async (ctx: OperationContext) =>\n            this._tracing.withSpan(\n              \"DocumentAnalysisClient.createAnalysisPoller-resume\",\n              definition.options,\n              async () => {\n                const { clientVersion, operationLocation, modelId } = JSON.parse(resumeFrom) as {\n                  clientVersion?: string;\n                  operationLocation: string;\n                  modelId: string;\n                };\n\n                if (!clientVersion || clientVersion !== SDK_VERSION) {\n                  throw new Error(\n                    [\n                      \"Cannot restore poller from a serialized state from a different version of the client\",\n                      `library (restoreFrom: '${clientVersion}', current: '${SDK_VERSION}').`,\n                    ].join(\" \")\n                  );\n                }\n\n                const result = await getAnalyzeResult(ctx, operationLocation);\n\n                return toDocumentAnalysisPollOperationState(\n                  definition,\n                  modelId,\n                  operationLocation,\n                  result\n                );\n              }\n            )\n        : // Otherwise, we'll start a new operation from the initialModelId\n          async (ctx: OperationContext) =>\n            this._tracing.withSpan(\n              \"DocumentAnalysisClient.createAnalysisPoller-start\",\n              definition.options,\n              async () => {\n                const { operationLocation } = await startOperation(ctx.abortSignal);\n\n                if (operationLocation === undefined) {\n                  throw new Error(\n                    \"Unable to start analysis operation: no Operation-Location received.\"\n                  );\n                }\n\n                const result = await getAnalyzeResult(ctx, operationLocation);\n\n                return toDocumentAnalysisPollOperationState(\n                  definition,\n                  definition.initialModelId,\n                  operationLocation,\n                  result\n                );\n              }\n            );\n\n    const poller = await lro<Result, DocumentAnalysisPollOperationState<Result>>(\n      {\n        init: toInit,\n        poll: async (ctx, { operationLocation, modelId }) =>\n          this._tracing.withSpan(\n            \"DocumentAnalysisClient.createAnalysisPoller-poll\",\n            {},\n            async () => {\n              const result = await getAnalyzeResult(ctx, operationLocation);\n\n              return toDocumentAnalysisPollOperationState(\n                definition,\n                modelId,\n                operationLocation,\n                result\n              );\n            }\n          ),\n        serialize: ({ operationLocation, modelId }) =>\n          JSON.stringify({ clientVersion: SDK_VERSION, id: modelId, operationLocation }),\n      },\n      definition.options.updateIntervalInMs,\n      definition.options.abortSignal\n    );\n\n    if (definition.options.onProgress !== undefined) {\n      poller.onProgress(definition.options.onProgress);\n      definition.options.onProgress(poller.getOperationState());\n    }\n\n    return poller;\n  }\n\n  // #endregion\n}\n\n/**\n * Produce an appropriate pair of content-type and analyzeRequest value for the analysis request.\n * @internal\n */\nfunction toAnalyzeRequest(\n  input: DocumentSource\n): [\"application/json\", AnalyzeDocumentRequest] | [ContentType, FormRecognizerRequestBody] {\n  switch (input.kind) {\n    case \"body\":\n      return [\"application/octet-stream\", input.body];\n    case \"url\":\n      return [\"application/json\", { urlSource: input.url }];\n    case \"base64\":\n      return [\"application/json\", { base64Source: input.base64 }];\n    default: {\n      const __exhaust: never = input;\n      throw new Error(`Unreachable 'toAnalyzeRequest' case: ${__exhaust}`);\n    }\n  }\n}\n\n/**\n * The input to a document analysis operation.\n */\n// type DocumentSource = DocumentBodySource | DocumentUrlSource | DocumentBase64Source;\n\nfunction source<K extends DocumentSource[\"kind\"]>(\n  kind: K,\n  value: Extract<DocumentSource, { kind: K }>[K & keyof Extract<DocumentSource, { kind: K }>]\n): DocumentSource {\n  return {\n    kind,\n    [kind]: value,\n  } as unknown as DocumentSource;\n}\n\n/**\n * The input to a document analysis operation.\n *\n * @internal\n */\ntype DocumentSource = {\n  [K in keyof DocumentSourceTypes]: {\n    /** The input kind. */\n    kind: K;\n  } & { [_ in K]: DocumentSourceTypes[K] };\n}[keyof DocumentSourceTypes];\n\n/**\n * A map of input discriminants to concrete input types.\n *\n * @internal\n */\ninterface DocumentSourceTypes {\n  /**\n   * A document buffer or stream to be uploaded in the request body.\n   */\n  body: FormRecognizerRequestBody;\n\n  /**\n   * A URL to a document to be analyzed.\n   */\n  url: string;\n\n  /**\n   * The data of a document to be analyzed. This is NOT base64-encoded, but will\n   * be base64-encoded by the client before uploading.\n   *\n   * NOTE: This is never used by the client because it is inefficient compared to direct uploads and does not currently\n   * support any features that `body` does not.\n   */\n  base64: Uint8Array;\n}\n"]}